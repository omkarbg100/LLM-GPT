{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":10570483,"datasetId":6540940,"databundleVersionId":10904655},{"sourceType":"datasetVersion","sourceId":783730,"datasetId":407960,"databundleVersionId":805278}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/openai-gpt2-weights/124M'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nprint(\"here it is The FineTunned Data \\n\")\nfor dirname, _, filenames in os.walk('/kaggle/input/datasets/imgcaptioning/instruction-data'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:51:48.842431Z","iopub.execute_input":"2026-02-21T11:51:48.842965Z","iopub.status.idle":"2026-02-21T11:51:48.858852Z","shell.execute_reply.started":"2026-02-21T11:51:48.842937Z","shell.execute_reply":"2026-02-21T11:51:48.858085Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/openai-gpt2-weights/124M/124M/hparams.json\n/kaggle/input/openai-gpt2-weights/124M/124M/model.ckpt.meta\n/kaggle/input/openai-gpt2-weights/124M/124M/model.ckpt.index\n/kaggle/input/openai-gpt2-weights/124M/124M/model.ckpt.data-00000-of-00001\n/kaggle/input/openai-gpt2-weights/124M/124M/encoder.json\n/kaggle/input/openai-gpt2-weights/124M/124M/vocab.bpe\n/kaggle/input/openai-gpt2-weights/124M/124M/checkpoint\nhere it is The FineTunned Data \n\n/kaggle/input/datasets/imgcaptioning/instruction-data/instruction-data.json\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Copyright (c) Sebastian Raschka\n# Adapted for Kaggle GPT-2 pretrained weights loading (NO DOWNLOAD)\n\nimport os\nimport json\nimport numpy as np\nimport tensorflow as tf\nimport tqdm\n\n\n# ==============================\n# Main loader (KAGGLE SAFE)\n# ==============================\ndef download_and_load_gpt2(model_size, models_dir):\n    \"\"\"\n    Loads GPT-2 weights from Kaggle input directory.\n    DOES NOT download anything.\n    \"\"\"\n\n    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n    if model_size not in allowed_sizes:\n        raise ValueError(f\"Model size must be one of {allowed_sizes}\")\n\n    # Kaggle already has files as:\n    # /kaggle/input/openai-gpt2-weights/124M/124M/*\n    model_dir = os.path.join(models_dir, model_size, model_size)\n\n    if not os.path.exists(model_dir):\n        raise FileNotFoundError(f\"Model directory not found: {model_dir}\")\n\n    # Load hyperparameters\n    hparams_path = os.path.join(model_dir, \"hparams.json\")\n    with open(hparams_path, \"r\", encoding=\"utf-8\") as f:\n        settings = json.load(f)\n\n    # Load TensorFlow checkpoint\n    ckpt_path = tf.train.latest_checkpoint(model_dir)\n    if ckpt_path is None:\n        raise FileNotFoundError(\"TensorFlow checkpoint not found.\")\n\n    params = load_gpt2_params_from_tf_ckpt(ckpt_path, settings)\n\n    return settings, params\n\n\n# ==============================\n# TF checkpoint → NumPy weights\n# ==============================\ndef load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n\n    for name, _ in tf.train.list_variables(ckpt_path):\n        array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n        parts = name.split(\"/\")[1:]  # remove \"model/\"\n\n        target = params\n        if parts[0].startswith(\"h\"):\n            layer = int(parts[0][1:])\n            target = params[\"blocks\"][layer]\n\n        for key in parts[1:-1]:\n            target = target.setdefault(key, {})\n\n        target[parts[-1]] = array\n\n    return params\n\n\n# ==============================\n# USAGE (KAGGLE)\n# ==============================\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:51:48.920450Z","iopub.execute_input":"2026-02-21T11:51:48.920735Z","iopub.status.idle":"2026-02-21T11:52:02.813168Z","shell.execute_reply.started":"2026-02-21T11:51:48.920711Z","shell.execute_reply":"2026-02-21T11:52:02.812588Z"}},"outputs":[{"name":"stderr","text":"2026-02-21 11:51:50.435167: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1771674710.621867      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1771674710.676607      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1771674711.104310      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771674711.104784      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771674711.104788      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1771674711.104790      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import tiktoken\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:02.814507Z","iopub.execute_input":"2026-02-21T11:52:02.815245Z","iopub.status.idle":"2026-02-21T11:52:06.461401Z","shell.execute_reply.started":"2026-02-21T11:52:02.815219Z","shell.execute_reply":"2026-02-21T11:52:06.460772Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# First Implemet The Tokenizer","metadata":{}},{"cell_type":"code","source":"\nclass GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.tokenizer = tokenizer\n        self.input_ids = []\n        self.target_ids = []\n\n        # Tokenize the entire text\n        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n\n        # Use a sliding window to chunk the book into overlapping sequences of max_length\n        for i in range(0, len(token_ids) - max_length, stride):\n            input_chunk = token_ids[i:i + max_length]\n            target_chunk = token_ids[i + 1: i + max_length + 1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.462289Z","iopub.execute_input":"2026-02-21T11:52:06.462861Z","iopub.status.idle":"2026-02-21T11:52:06.468156Z","shell.execute_reply.started":"2026-02-21T11:52:06.462835Z","shell.execute_reply":"2026-02-21T11:52:06.467590Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def create_dataloader_v1(txt, batch_size=4, max_length=256,\n                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n    # Initialize the tokenizer\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n\n    # Create dataset\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n\n    # Create dataloader\n    dataloader = DataLoader(\n        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n\n    return dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.469735Z","iopub.execute_input":"2026-02-21T11:52:06.469965Z","iopub.status.idle":"2026-02-21T11:52:06.483617Z","shell.execute_reply.started":"2026-02-21T11:52:06.469945Z","shell.execute_reply":"2026-02-21T11:52:06.482891Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n        super().__init__()\n        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n\n        self.d_out = d_out\n        self.num_heads = num_heads\n        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n\n    def forward(self, x):\n        b, num_tokens, d_in = x.shape\n\n        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n\n        # We implicitly split the matrix by adding a `num_heads` dimension\n        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n\n        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n        keys = keys.transpose(1, 2)\n        queries = queries.transpose(1, 2)\n        values = values.transpose(1, 2)\n\n        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n\n        # Original mask truncated to the number of tokens and converted to boolean\n        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n\n        # Use the mask to fill attention scores\n        attn_scores.masked_fill_(mask_bool, -torch.inf)\n\n        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n        attn_weights = self.dropout(attn_weights)\n\n        # Shape: (b, num_tokens, num_heads, head_dim)\n        context_vec = (attn_weights @ values).transpose(1, 2)\n\n        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n        context_vec = self.out_proj(context_vec)  # optional projection\n\n        return context_vec\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.484661Z","iopub.execute_input":"2026-02-21T11:52:06.484884Z","iopub.status.idle":"2026-02-21T11:52:06.495585Z","shell.execute_reply.started":"2026-02-21T11:52:06.484862Z","shell.execute_reply":"2026-02-21T11:52:06.495047Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self, emb_dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.scale = nn.Parameter(torch.ones(emb_dim))\n        self.shift = nn.Parameter(torch.zeros(emb_dim))\n\n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n        return self.scale * norm_x + self.shift\n\n\nclass GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n            (x + 0.044715 * torch.pow(x, 3))\n        ))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.496497Z","iopub.execute_input":"2026-02-21T11:52:06.496853Z","iopub.status.idle":"2026-02-21T11:52:06.511250Z","shell.execute_reply.started":"2026-02-21T11:52:06.496818Z","shell.execute_reply":"2026-02-21T11:52:06.510597Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\nclass FeedForward(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n            GELU(),\n            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.512149Z","iopub.execute_input":"2026-02-21T11:52:06.512410Z","iopub.status.idle":"2026-02-21T11:52:06.525815Z","shell.execute_reply.started":"2026-02-21T11:52:06.512390Z","shell.execute_reply":"2026-02-21T11:52:06.525137Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\nclass TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.att = MultiHeadAttention(\n            d_in=cfg[\"emb_dim\"],\n            d_out=cfg[\"emb_dim\"],\n            context_length=cfg[\"context_length\"],\n            num_heads=cfg[\"n_heads\"],\n            dropout=cfg[\"drop_rate\"],\n            qkv_bias=cfg[\"qkv_bias\"])\n        self.ff = FeedForward(cfg)\n        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, x):\n        # Shortcut connection for attention block\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_shortcut(x)\n        x = x + shortcut  # Add the original input back\n\n        # Shortcut connection for feed-forward block\n        shortcut = x\n        x = self.norm2(x)\n        x = self.ff(x)\n        x = self.drop_shortcut(x)\n        x = x + shortcut  # Add the original input back\n\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.526878Z","iopub.execute_input":"2026-02-21T11:52:06.527475Z","iopub.status.idle":"2026-02-21T11:52:06.537114Z","shell.execute_reply.started":"2026-02-21T11:52:06.527452Z","shell.execute_reply":"2026-02-21T11:52:06.536437Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"\nclass GPTModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n\n        self.trf_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n\n        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n\n    def forward(self, in_idx):\n        batch_size, seq_len = in_idx.shape\n        tok_embeds = self.tok_emb(in_idx)\n        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_emb(x)\n        x = self.trf_blocks(x)\n        x = self.final_norm(x)\n        logits = self.out_head(x)\n        return logits\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.538100Z","iopub.execute_input":"2026-02-21T11:52:06.538365Z","iopub.status.idle":"2026-02-21T11:52:06.554027Z","shell.execute_reply.started":"2026-02-21T11:52:06.538336Z","shell.execute_reply":"2026-02-21T11:52:06.553505Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"\ndef text_to_token_ids(text, tokenizer):\n    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n    return encoded_tensor\n\ndef token_ids_to_text(token_ids, tokenizer):\n    flat = token_ids.squeeze(0) # remove batch dimension\n    return tokenizer.decode(flat.tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.556493Z","iopub.execute_input":"2026-02-21T11:52:06.556711Z","iopub.status.idle":"2026-02-21T11:52:06.566026Z","shell.execute_reply.started":"2026-02-21T11:52:06.556692Z","shell.execute_reply":"2026-02-21T11:52:06.565410Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\ndef generate_text_simple(model, idx, max_new_tokens, context_size):\n    # idx is (B, T) array of indices in the current context\n    for _ in range(max_new_tokens):\n\n        # Crop current context if it exceeds the supported context size\n        # E.g., if LLM supports only 5 tokens, and the context size is 10\n        # then only the last 5 tokens are used as context\n        idx_cond = idx[:, -context_size:]\n\n        # Get the predictions\n        with torch.no_grad():\n            logits = model(idx_cond)\n\n        # Focus only on the last time step\n        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n        print(logits.size(),\"\\n\")\n        logits = logits[:, -1, :]\n\n        # Get the idx of the vocab entry with the highest logits value\n        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n\n        # Append sampled index to the running sequence\n        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n\n    return idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.566857Z","iopub.execute_input":"2026-02-21T11:52:06.567077Z","iopub.status.idle":"2026-02-21T11:52:06.582175Z","shell.execute_reply.started":"2026-02-21T11:52:06.567058Z","shell.execute_reply":"2026-02-21T11:52:06.581628Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"GPT_CONFIG_124M = {\n    \"vocab_size\": 50257,   # Vocabulary size\n    \"context_length\": 1024, # Shortened context length (orig: 1024)\n    \"emb_dim\": 768,        # Embedding dimension\n    \"n_heads\": 12,         # Number of attention heads\n    \"n_layers\": 12,        # Number of layers\n    \"drop_rate\": 0.1,      # Dropout rate\n    \"qkv_bias\": False      # Query-key-value bias\n}\n\ntokenizer = tiktoken.get_encoding(\"gpt2\")\n\ndef main():\n\n\n    torch.manual_seed(123)\n    model = GPTModel(GPT_CONFIG_124M)\n    model.eval()  # disable dropout\n\n    start_context = \"Hello, I am omkar who are you\"\n\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n    encoded = tokenizer.encode(start_context)\n    encoded_tensor = torch.tensor([encoded])\n    #.unsqueeze(0)\n\n    \n    print(f\"\\n{50*'='}\\n{22*' '}IN\")\n    print(\"\\nInput text:\", start_context)\n    print(\"Encoded input text:\", encoded)\n    print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n    print(f\"\\n{50*'='}\")\n    # return 0\n    out = generate_text_simple(\n        model=model,\n        idx=encoded_tensor,\n        max_new_tokens=2,\n        context_size=GPT_CONFIG_124M[\"context_length\"]\n    )\n    decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n    \n    print(f\"\\n\\n{50*'='}\\n{22*' '}OUT\\n\")\n    print(\"\\nOutput:\", out)\n    print(\"Output length:\", len(out[0]))\n    print(\"Output text:\", decoded_text)\n    print(f\"\\n{50*'='}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:06.582997Z","iopub.execute_input":"2026-02-21T11:52:06.583190Z","iopub.status.idle":"2026-02-21T11:52:08.122254Z","shell.execute_reply.started":"2026-02-21T11:52:06.583172Z","shell.execute_reply":"2026-02-21T11:52:08.121697Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:08.123226Z","iopub.execute_input":"2026-02-21T11:52:08.123646Z","iopub.status.idle":"2026-02-21T11:52:09.686963Z","shell.execute_reply.started":"2026-02-21T11:52:08.123613Z","shell.execute_reply":"2026-02-21T11:52:09.686364Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\n                      IN\n\nInput text: Hello, I am omkar who are you\nEncoded input text: [15496, 11, 314, 716, 39030, 21070, 508, 389, 345]\nencoded_tensor.shape: torch.Size([1, 9])\n\n==================================================\ntorch.Size([1, 9, 50257]) \n\ntorch.Size([1, 10, 50257]) \n\n\n\n==================================================\n                      OUT\n\n\nOutput: tensor([[15496,    11,   314,   716, 39030, 21070,   508,   389,   345, 41631,\n         50182]])\nOutput length: 11\nOutput text: Hello, I am omkar who are youTogether Gö\n\n==================================================\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def calc_loss_batch(input_batch, target_batch, model, device):\n    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n    logits = model(input_batch)\n    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n    return loss\n\n\ndef calc_loss_loader(data_loader, model, device, num_batches=None):\n    total_loss = 0.\n    if len(data_loader) == 0:\n        return float(\"nan\")\n    elif num_batches is None:\n        num_batches = len(data_loader)\n    else:\n        # Reduce the number of batches to match the total number of batches in the data loader\n        # if num_batches exceeds the number of batches in the data loader\n        num_batches = min(num_batches, len(data_loader))\n    for i, (input_batch, target_batch) in enumerate(data_loader):\n        if i < num_batches:\n            loss = calc_loss_batch(input_batch, target_batch, model, device)\n            total_loss += loss.item()\n        else:\n            break\n    return total_loss / num_batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:09.687957Z","iopub.execute_input":"2026-02-21T11:52:09.688466Z","iopub.status.idle":"2026-02-21T11:52:09.693807Z","shell.execute_reply.started":"2026-02-21T11:52:09.688442Z","shell.execute_reply":"2026-02-21T11:52:09.693084Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n                       eval_freq, eval_iter, start_context, tokenizer):\n    # Initialize lists to track losses and tokens seen\n    train_losses, val_losses, track_tokens_seen = [], [], []\n    tokens_seen, global_step = 0, -1\n\n    # Main training loop\n    for epoch in range(num_epochs):\n        model.train()  # Set model to training mode\n        \n        for input_batch, target_batch in train_loader:\n            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n            loss = calc_loss_batch(input_batch, target_batch, model, device)\n            loss.backward() # Calculate loss gradients\n            optimizer.step() # Update model weights using loss gradients\n            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n            global_step += 1\n\n            # Optional evaluation step\n            if global_step % eval_freq == 0: \n                train_loss, val_loss = evaluate_model(\n                    model, train_loader, val_loader, device, eval_iter)\n                train_losses.append(train_loss)\n                val_losses.append(val_loss)\n                track_tokens_seen.append(tokens_seen)\n                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n\n        # Print a sample text after each epoch\n        generate_and_print_sample(\n            model, tokenizer, device, start_context\n        )\n\n    return train_losses, val_losses, track_tokens_seen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:09.694747Z","iopub.execute_input":"2026-02-21T11:52:09.694961Z","iopub.status.idle":"2026-02-21T11:52:09.710139Z","shell.execute_reply.started":"2026-02-21T11:52:09.694942Z","shell.execute_reply":"2026-02-21T11:52:09.709472Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n    model.eval()\n    with torch.no_grad():\n        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n    model.train()\n    return train_loss, val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:09.711110Z","iopub.execute_input":"2026-02-21T11:52:09.711482Z","iopub.status.idle":"2026-02-21T11:52:09.723774Z","shell.execute_reply.started":"2026-02-21T11:52:09.711460Z","shell.execute_reply":"2026-02-21T11:52:09.723223Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def generate_and_print_sample(model, tokenizer, device, start_context):\n    model.eval()\n    context_size = model.pos_emb.weight.shape[0]\n    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n    with torch.no_grad():\n        token_ids = generate_text_simple(\n            model=model, idx=encoded,\n            max_new_tokens=50, context_size=context_size\n        )\n    decoded_text = token_ids_to_text(token_ids, tokenizer)\n    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n    model.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:09.724758Z","iopub.execute_input":"2026-02-21T11:52:09.725053Z","iopub.status.idle":"2026-02-21T11:52:09.734712Z","shell.execute_reply.started":"2026-02-21T11:52:09.725021Z","shell.execute_reply":"2026-02-21T11:52:09.734015Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import os\nimport urllib.request\n\nfile_path = \"the-verdict.txt\"\nurl = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n\nif not os.path.exists(file_path):\n    with urllib.request.urlopen(url) as response:\n        text_data = response.read().decode('utf-8')\n    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n        file.write(text_data)\nelse:\n    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n        text_data = file.read()\n\n\n\n\n# Train/validation ratio\ntrain_ratio = 0.90\nsplit_idx = int(train_ratio * len(text_data))\ntrain_data = text_data[:split_idx]\nval_data = text_data[split_idx:]\n\n\ntorch.manual_seed(123)\n\ntrain_loader = create_dataloader_v1(\n    train_data,\n    batch_size=2,\n    max_length=GPT_CONFIG_124M[\"context_length\"],\n    stride=GPT_CONFIG_124M[\"context_length\"],\n    drop_last=True,\n    shuffle=True,\n    num_workers=0\n)\n\nval_loader = create_dataloader_v1(\n    val_data,\n    batch_size=2,\n    max_length=GPT_CONFIG_124M[\"context_length\"],\n    stride=GPT_CONFIG_124M[\"context_length\"],\n    drop_last=False,\n    shuffle=False,\n    num_workers=0\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:09.735520Z","iopub.execute_input":"2026-02-21T11:52:09.735757Z","iopub.status.idle":"2026-02-21T11:52:09.790014Z","shell.execute_reply.started":"2026-02-21T11:52:09.735738Z","shell.execute_reply":"2026-02-21T11:52:09.789485Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:09.790800Z","iopub.execute_input":"2026-02-21T11:52:09.791013Z","iopub.status.idle":"2026-02-21T11:52:09.844320Z","shell.execute_reply.started":"2026-02-21T11:52:09.790993Z","shell.execute_reply":"2026-02-21T11:52:09.843566Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\ntorch.manual_seed(123)\nmodel = GPTModel(GPT_CONFIG_124M)\nmodel.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n\nnum_epochs = 10\n#train_losses, val_losses, tokens_seen = train_model_simple(\n#    model, train_loader, val_loader, optimizer, device,\n#    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n#    start_context=\"Every effort moves you\", tokenizer=tokenizer\n#)\n\n# Note:\n# Uncomment the following code to show the execution time\nend_time = time.time()\nexecution_time_minutes = (end_time - start_time) / 60\nprint(f\"Training completed in {execution_time_minutes:.2f} minutes.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:09.845222Z","iopub.execute_input":"2026-02-21T11:52:09.845549Z","iopub.status.idle":"2026-02-21T11:52:13.857811Z","shell.execute_reply.started":"2026-02-21T11:52:09.845526Z","shell.execute_reply":"2026-02-21T11:52:13.857150Z"}},"outputs":[{"name":"stdout","text":"Training completed in 0.07 minutes.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Note:\n# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n# However, the resulting loss values may be slightly different.\n\n#if torch.cuda.is_available():\n#    device = torch.device(\"cuda\")\n#elif torch.backends.mps.is_available():\n#    device = torch.device(\"mps\")\n#else:\n#    device = torch.device(\"cpu\")\n#\n# print(f\"Using {device} device.\")\nmodel = GPTModel(GPT_CONFIG_124M)\n\nmodel.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n\n\ntorch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n\nwith torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n    train_loss = calc_loss_loader(train_loader, model, device)\n    val_loss = calc_loss_loader(val_loader, model, device)\n\nprint(\"Training loss:\", train_loss)\nprint(\"Validation loss:\", val_loss)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:13.858747Z","iopub.execute_input":"2026-02-21T11:52:13.859276Z","iopub.status.idle":"2026-02-21T11:52:15.812061Z","shell.execute_reply.started":"2026-02-21T11:52:13.859250Z","shell.execute_reply":"2026-02-21T11:52:15.811448Z"}},"outputs":[{"name":"stdout","text":"Training loss: 10.996783256530762\nValidation loss: nan\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"def generate_text_simple(model, idx, max_new_tokens, context_size):\n    device = next(model.parameters()).device\n    idx = idx.to(device)\n\n    # idx is (B, T)\n    for _ in range(max_new_tokens):\n\n        # Crop context\n        idx_cond = idx[:, -context_size:]\n\n        # Forward pass\n        with torch.no_grad():\n            logits = model(idx_cond)\n\n        # (B, T, vocab) → (B, vocab)\n        logits = logits[:, -1, :]\n\n        # Greedy sampling\n        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n\n        # Append token\n        idx = torch.cat((idx, idx_next), dim=1)\n\n    return idx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:15.812891Z","iopub.execute_input":"2026-02-21T11:52:15.813084Z","iopub.status.idle":"2026-02-21T11:52:15.818486Z","shell.execute_reply.started":"2026-02-21T11:52:15.813066Z","shell.execute_reply":"2026-02-21T11:52:15.817592Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"tokenizer = tiktoken.get_encoding(\"gpt2\")\n\ntoken_ids = generate_text_simple(\n    model=model,\n    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n    max_new_tokens=25,\n    context_size=GPT_CONFIG_124M[\"context_length\"]\n)\n\nprint(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:15.819461Z","iopub.execute_input":"2026-02-21T11:52:15.819680Z","iopub.status.idle":"2026-02-21T11:52:16.199970Z","shell.execute_reply.started":"2026-02-21T11:52:15.819660Z","shell.execute_reply":"2026-02-21T11:52:16.199325Z"}},"outputs":[{"name":"stdout","text":"Output text:\n Every effort moves youacebook accommodatingocard whippedcampLondon civilianKR adject anchorIll interpretation803 Psychology explos477reqtchIDSteitus comment authored hierulative\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n\n    # For-loop is the same as before: Get logits, and only focus on last time step\n    for _ in range(max_new_tokens):\n        idx_cond = idx[:, -context_size:]\n        with torch.no_grad():\n            logits = model(idx_cond)\n        logits = logits[:, -1, :]\n\n        # New: Filter logits with top_k sampling\n        if top_k is not None:\n            # Keep only top_k values\n            top_logits, _ = torch.topk(logits, top_k)\n            min_val = top_logits[:, -1]\n            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n\n        # New: Apply temperature scaling\n        if temperature > 0.0:\n            logits = logits / temperature\n\n            # Apply softmax to get probabilities\n            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n\n            # Sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n\n        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n        else:\n            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n\n        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n            break\n\n        # Same as before: append sampled index to the running sequence\n        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n\n    return idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:16.200780Z","iopub.execute_input":"2026-02-21T11:52:16.201041Z","iopub.status.idle":"2026-02-21T11:52:16.207289Z","shell.execute_reply.started":"2026-02-21T11:52:16.201017Z","shell.execute_reply":"2026-02-21T11:52:16.206555Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# Now we will Use GPT-2 Weights for our Model","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport tqdm\n\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"tqdm version:\", tqdm.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:16.208193Z","iopub.execute_input":"2026-02-21T11:52:16.208552Z","iopub.status.idle":"2026-02-21T11:52:16.221672Z","shell.execute_reply.started":"2026-02-21T11:52:16.208522Z","shell.execute_reply":"2026-02-21T11:52:16.221119Z"}},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.19.0\ntqdm version: 4.67.1\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"#from gpt_download3 import download_and_load_gpt2\n\n\n# ../kaggle/input/openai-gpt2-weights/124M/124M\n# /kaggle/input/openai-gpt2-weights/124M/124M/hparams.json\n\nMODEL_DIR = \"/kaggle/input/openai-gpt2-weights\"\n\nsettings, params = download_and_load_gpt2(\n    model_size=\"124M\",\n    models_dir=MODEL_DIR\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:16.222536Z","iopub.execute_input":"2026-02-21T11:52:16.222766Z","iopub.status.idle":"2026-02-21T11:52:21.916911Z","shell.execute_reply.started":"2026-02-21T11:52:16.222747Z","shell.execute_reply":"2026-02-21T11:52:21.916320Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Define model configurations in a dictionary for compactness\nmodel_configs = {\n    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n}\n\n# Copy the base configuration and update with specific model settings\nmodel_name = \"gpt2-small (124M)\"  # Example model name\nNEW_CONFIG = GPT_CONFIG_124M.copy()\nNEW_CONFIG.update(model_configs[model_name])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:21.917857Z","iopub.execute_input":"2026-02-21T11:52:21.918102Z","iopub.status.idle":"2026-02-21T11:52:21.922803Z","shell.execute_reply.started":"2026-02-21T11:52:21.918068Z","shell.execute_reply":"2026-02-21T11:52:21.922128Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\ngpt = GPTModel(NEW_CONFIG)\ngpt.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:21.926071Z","iopub.execute_input":"2026-02-21T11:52:21.926306Z","iopub.status.idle":"2026-02-21T11:52:23.155177Z","shell.execute_reply.started":"2026-02-21T11:52:21.926264Z","shell.execute_reply":"2026-02-21T11:52:23.154589Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"GPTModel(\n  (tok_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(1024, 768)\n  (drop_emb): Dropout(p=0.1, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"def assign(left, right):\n    if left.shape != right.shape:\n        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n    return torch.nn.Parameter(torch.tensor(right))\n\n\nimport numpy as np\n\ndef load_weights_into_gpt(gpt, params):\n    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n    \n    for b in range(len(params[\"blocks\"])):\n        q_w, k_w, v_w = np.split(\n            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n        gpt.trf_blocks[b].att.W_query.weight = assign(\n            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n        gpt.trf_blocks[b].att.W_key.weight = assign(\n            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n        gpt.trf_blocks[b].att.W_value.weight = assign(\n            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n\n        q_b, k_b, v_b = np.split(\n            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n        gpt.trf_blocks[b].att.W_query.bias = assign(\n            gpt.trf_blocks[b].att.W_query.bias, q_b)\n        gpt.trf_blocks[b].att.W_key.bias = assign(\n            gpt.trf_blocks[b].att.W_key.bias, k_b)\n        gpt.trf_blocks[b].att.W_value.bias = assign(\n            gpt.trf_blocks[b].att.W_value.bias, v_b)\n\n        gpt.trf_blocks[b].att.out_proj.weight = assign(\n            gpt.trf_blocks[b].att.out_proj.weight, \n            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n        gpt.trf_blocks[b].att.out_proj.bias = assign(\n            gpt.trf_blocks[b].att.out_proj.bias, \n            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n\n        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n            gpt.trf_blocks[b].ff.layers[0].weight, \n            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n            gpt.trf_blocks[b].ff.layers[0].bias, \n            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n            gpt.trf_blocks[b].ff.layers[2].weight, \n            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n            gpt.trf_blocks[b].ff.layers[2].bias, \n            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n\n        gpt.trf_blocks[b].norm1.scale = assign(\n            gpt.trf_blocks[b].norm1.scale, \n            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n        gpt.trf_blocks[b].norm1.shift = assign(\n            gpt.trf_blocks[b].norm1.shift, \n            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n        gpt.trf_blocks[b].norm2.scale = assign(\n            gpt.trf_blocks[b].norm2.scale, \n            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n        gpt.trf_blocks[b].norm2.shift = assign(\n            gpt.trf_blocks[b].norm2.shift, \n            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n\n    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:23.156090Z","iopub.execute_input":"2026-02-21T11:52:23.156388Z","iopub.status.idle":"2026-02-21T11:52:23.168262Z","shell.execute_reply.started":"2026-02-21T11:52:23.156366Z","shell.execute_reply":"2026-02-21T11:52:23.167535Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"load_weights_into_gpt(gpt, params)\ngpt.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:23.169195Z","iopub.execute_input":"2026-02-21T11:52:23.169516Z","iopub.status.idle":"2026-02-21T11:52:23.572300Z","shell.execute_reply.started":"2026-02-21T11:52:23.169486Z","shell.execute_reply":"2026-02-21T11:52:23.571694Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"GPTModel(\n  (tok_emb): Embedding(50257, 768)\n  (pos_emb): Embedding(1024, 768)\n  (drop_emb): Dropout(p=0.1, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=768, out_features=768, bias=True)\n        (W_key): Linear(in_features=768, out_features=768, bias=True)\n        (W_value): Linear(in_features=768, out_features=768, bias=True)\n        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=768, out_features=3072, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=3072, out_features=768, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"torch.manual_seed(123)\n\ntoken_ids = generate(\n    model=gpt,\n    idx=text_to_token_ids(\"Photosynthesis is the essential biological process \", tokenizer).to(device),\n    max_new_tokens=50,\n    context_size=NEW_CONFIG[\"context_length\"],\n    top_k=50,\n    temperature=1.4\n)\n\nprint(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:52:23.573082Z","iopub.execute_input":"2026-02-21T11:52:23.573344Z","iopub.status.idle":"2026-02-21T11:52:24.395472Z","shell.execute_reply.started":"2026-02-21T11:52:23.573314Z","shell.execute_reply":"2026-02-21T11:52:24.394732Z"}},"outputs":[{"name":"stdout","text":"Output text:\n Photosynthesis is the essential biological process  and the most basic process because it produces photosynthetic biomass of living organisms\nThere are at least 12 photosynthetic processes including photosensitivity, red colouration and photopractivity\nIf you don't feed a diet that is dominated by\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# From Here we will be Working On instruction Fintunning ","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport json\nimport os\nimport requests\n\ndef download_and_load_file(file_path, url):\n    if not os.path.exists(file_path):\n        response = requests.get(url, timeout=30)\n        response.raise_for_status()\n        text_data = response.text\n        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n            file.write(text_data)\n\n    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n        data = json.load(file)\n    return data\n\nfile_path=\"../input/datasets/imgcaptioning/instruction-data/instruction-data.json\"\nurl = (\n    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n)\ndata = download_and_load_file(file_path, url)\nprint(\"Number of entries:\", len(data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:56:26.601318Z","iopub.execute_input":"2026-02-21T11:56:26.601957Z","iopub.status.idle":"2026-02-21T11:56:26.618673Z","shell.execute_reply.started":"2026-02-21T11:56:26.601926Z","shell.execute_reply":"2026-02-21T11:56:26.618069Z"}},"outputs":[{"name":"stdout","text":"Number of entries: 1100\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"print(\"Example entry:\\n\", data[50])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T11:57:02.341016Z","iopub.execute_input":"2026-02-21T11:57:02.341762Z","iopub.status.idle":"2026-02-21T11:57:02.345914Z","shell.execute_reply.started":"2026-02-21T11:57:02.341734Z","shell.execute_reply":"2026-02-21T11:57:02.344941Z"}},"outputs":[{"name":"stdout","text":"Example entry:\n {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"**Here We will be Using The Alpaca-style prompt formatting**\n\nbelow Image Shows what we will be doing with the Data \n","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/09.webp?1\" width=400px>","metadata":{}},{"cell_type":"code","source":"def format_input(entry):\n    instruction_text = (\n        f\"Below is an instruction that describes a task. \"\n        f\"Write a response that appropriately completes the request.\"\n        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n    )\n\n    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n\n    return instruction_text + input_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:44:08.121915Z","iopub.execute_input":"2026-02-21T12:44:08.122219Z","iopub.status.idle":"2026-02-21T12:44:08.126511Z","shell.execute_reply.started":"2026-02-21T12:44:08.122195Z","shell.execute_reply":"2026-02-21T12:44:08.125927Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\n\nclass InstructionDataset(Dataset):\n    def __init__(self, data, tokenizer):\n        self.data = data\n\n        # Pre-tokenize texts\n        self.encoded_texts = []\n        for entry in data:\n            instruction_plus_input = format_input(entry)\n            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n            full_text = instruction_plus_input + response_text\n            self.encoded_texts.append(\n                tokenizer.encode(full_text)\n            )\n\n    def __getitem__(self, index):\n        return self.encoded_texts[index]\n\n    def __len__(self):\n        return len(self.data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:44:12.003685Z","iopub.execute_input":"2026-02-21T12:44:12.003968Z","iopub.status.idle":"2026-02-21T12:44:12.009532Z","shell.execute_reply.started":"2026-02-21T12:44:12.003945Z","shell.execute_reply":"2026-02-21T12:44:12.008619Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"**Split the Data into Traning , Testing and Validation Data**","metadata":{}},{"cell_type":"code","source":"train_portion = int(len(data) * 0.85)  # 85% for training\ntest_portion = int(len(data) * 0.1)    # 10% for testing\nval_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n\ntrain_data = data[:train_portion]\ntest_data = data[train_portion:train_portion + test_portion]\nval_data = data[train_portion + test_portion:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:44:18.027026Z","iopub.execute_input":"2026-02-21T12:44:18.027617Z","iopub.status.idle":"2026-02-21T12:44:18.031858Z","shell.execute_reply.started":"2026-02-21T12:44:18.027580Z","shell.execute_reply":"2026-02-21T12:44:18.031139Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"def custom_collate_fn(\n    batch,\n    pad_token_id=50256,\n    ignore_index=-100,\n    allowed_max_length=None,\n    device=\"cpu\"\n):\n    # Find the longest sequence in the batch\n    batch_max_length = max(len(item)+1 for item in batch)\n\n    # Pad and prepare inputs and targets\n    inputs_lst, targets_lst = [], []\n\n    for item in batch:\n        new_item = item.copy()\n        # Add an <|endoftext|> token\n        new_item += [pad_token_id]\n        # Pad sequences to max_length\n        padded = (\n            new_item + [pad_token_id] *\n            (batch_max_length - len(new_item))\n        )\n        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n\n        # New: Replace all but the first padding tokens in targets by ignore_index\n        mask = targets == pad_token_id\n        indices = torch.nonzero(mask).squeeze()\n        if indices.numel() > 1:\n            targets[indices[1:]] = ignore_index\n\n        # New: Optionally truncate to maximum sequence length\n        if allowed_max_length is not None:\n            inputs = inputs[:allowed_max_length]\n            targets = targets[:allowed_max_length]\n\n        inputs_lst.append(inputs)\n        targets_lst.append(targets)\n\n    # Convert list of inputs and targets to tensors and transfer to target device\n    inputs_tensor = torch.stack(inputs_lst).to(device)\n    targets_tensor = torch.stack(targets_lst).to(device)\n\n    return inputs_tensor, targets_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:44:21.449963Z","iopub.execute_input":"2026-02-21T12:44:21.450814Z","iopub.status.idle":"2026-02-21T12:44:21.457187Z","shell.execute_reply.started":"2026-02-21T12:44:21.450780Z","shell.execute_reply":"2026-02-21T12:44:21.456431Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"from functools import partial\n\ncustomized_collate_fn = partial(\n    custom_collate_fn,\n    device=device,\n    allowed_max_length=1024\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:44:30.396060Z","iopub.execute_input":"2026-02-21T12:44:30.396376Z","iopub.status.idle":"2026-02-21T12:44:30.400037Z","shell.execute_reply.started":"2026-02-21T12:44:30.396350Z","shell.execute_reply":"2026-02-21T12:44:30.399514Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n\nnum_workers = 0\nbatch_size = 8\n\ntorch.manual_seed(123)\n\ntrain_dataset = InstructionDataset(train_data, tokenizer)\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    collate_fn=customized_collate_fn,\n    shuffle=True,\n    drop_last=True,\n    num_workers=num_workers\n)\n\nval_dataset = InstructionDataset(val_data, tokenizer)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=batch_size,\n    collate_fn=customized_collate_fn,\n    shuffle=False,\n    drop_last=False,\n    num_workers=num_workers\n)\n\ntest_dataset = InstructionDataset(test_data, tokenizer)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    collate_fn=customized_collate_fn,\n    shuffle=False,\n    drop_last=False,\n    num_workers=num_workers\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:44:33.277646Z","iopub.execute_input":"2026-02-21T12:44:33.277927Z","iopub.status.idle":"2026-02-21T12:44:33.319630Z","shell.execute_reply.started":"2026-02-21T12:44:33.277904Z","shell.execute_reply":"2026-02-21T12:44:33.318856Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"\nBASE_CONFIG = {\n    \"vocab_size\": 50257,     # Vocabulary size\n    \"context_length\": 1024,  # Context length\n    \"drop_rate\": 0.0,        # Dropout rate\n    \"qkv_bias\": True         # Query-key-value bias\n}\n\nmodel_configs = {\n    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n}\n\nCHOOSE_MODEL = \"gpt2-medium (355M)\"\n\nBASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n\nmodel_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\nsettings, params = download_and_load_gpt2(\n    model_size=model_size,\n    models_dir=\"/kaggle/input/openai-gpt2-weights\"\n)\n\nmodel = GPTModel(BASE_CONFIG)\nload_weights_into_gpt(model, params)\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:54:50.205017Z","iopub.execute_input":"2026-02-21T12:54:50.205686Z","iopub.status.idle":"2026-02-21T12:55:03.812876Z","shell.execute_reply.started":"2026-02-21T12:54:50.205656Z","shell.execute_reply":"2026-02-21T12:55:03.812298Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"GPTModel(\n  (tok_emb): Embedding(50257, 1024)\n  (pos_emb): Embedding(1024, 1024)\n  (drop_emb): Dropout(p=0.0, inplace=False)\n  (trf_blocks): Sequential(\n    (0): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (1): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (2): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (3): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (4): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (5): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (6): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (7): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (8): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (9): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (10): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (11): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (12): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (13): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (14): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (15): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (16): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (17): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (18): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (19): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (20): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (21): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (22): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n    (23): TransformerBlock(\n      (att): MultiHeadAttention(\n        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (ff): FeedForward(\n        (layers): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=True)\n          (1): GELU()\n          (2): Linear(in_features=4096, out_features=1024, bias=True)\n        )\n      )\n      (norm1): LayerNorm()\n      (norm2): LayerNorm()\n      (drop_shortcut): Dropout(p=0.0, inplace=False)\n    )\n  )\n  (final_norm): LayerNorm()\n  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"input_text = format_input(val_data[0])\nprint(input_text)\n\ntoken_ids = generate(\n    model=model,\n    idx=text_to_token_ids(input_text, tokenizer),\n    max_new_tokens=35,\n    context_size=BASE_CONFIG[\"context_length\"],\n    eos_id=50256,\n)\ngenerated_text = token_ids_to_text(token_ids, tokenizer)\nresponse_text = (\n    generated_text[len(input_text):]\n    .replace(\"### Response:\", \"\")\n    .strip()\n)\nprint(\"----------------\")\nprint(response_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-21T12:57:57.881051Z","iopub.execute_input":"2026-02-21T12:57:57.881756Z","iopub.status.idle":"2026-02-21T12:58:10.609168Z","shell.execute_reply.started":"2026-02-21T12:57:57.881726Z","shell.execute_reply":"2026-02-21T12:58:10.608474Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nConvert the active sentence to passive: 'The chef cooks the meal every day.'\n----------------\nThe chef cooks the meal every day.\n\n### Instruction:\n\nConvert the active sentence to passive: 'The chef cooks the\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}